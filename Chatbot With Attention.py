# -*- coding: utf-8 -*-
"""Chatbot with Attention

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BDOGuTqipLG1wTiLEQ6YqqzYn566DIHx

# **Load and process data**
"""

import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import os
import time
import json

path_to_file = tf.keras.utils.get_file('movies.json', 'https://raw.githubusercontent.com/google-research-datasets/Taskmaster/master/TM-2-2020/data/movies.json')

with open(path_to_file) as file:
  data = json.load(file)

user = list()
assistant = list()
sentence = '<start>'

for conversation in data:
  user_has_not_started = True
  # The conversation starts with the user speaks first
  user_is_talking = True
  assistant_is_talking = False

  for utterance in conversation['utterances']:
    if utterance['speaker'] == 'ASSISTANT' and user_has_not_started:
      continue
    else:
      user_has_not_started = False
    
      # process the utterance  
      buffer = utterance['text']
      
      # These lines are for grouping special segments into one group. However,
      # that would require implementing another model for the machine to recognize
      # those model from the user. For the scope of this project, I'm going to pause here

      if utterance.get('segments'):
        for segment in utterance.get('segments'):
          annotation = segment.get('annotations')[0]['name']
          annotation = '<' + annotation.replace('.','<>').replace('_','<>') + '>'
          buffer = buffer.replace(segment.get('text'), annotation)
      
      if utterance['speaker'] == 'USER':
        if assistant_is_talking:
          # finish assistant's sentence
          sentence = ' '.join(sentence.split(' ')[:-1]) + ' ' + '<end>'
          assistant.append(sentence)
          assistant_is_talking = False

          # reset the sentence for user
          sentence = '<start>'
          user_is_talking = True
      
      if utterance['speaker'] == 'ASSISTANT':
        if user_is_talking:
          # finish user's sentence
          sentence = ' '.join(sentence.split(' ')[:-1]) + ' ' + '<end>'
          user.append(sentence)
          user_is_talking = False

          # reset the sentence for assistant
          sentence = '<start>'
          assistant_is_talking = True
          
      # append to the sentence
      sentence = sentence + ' ' + buffer + ' ' + '<pause>'
  
  if assistant_is_talking:
    sentence = ' '.join(sentence.split(' ')[:-1]) + ' ' + '<end>'
    assistant.append(sentence)
  
print('Lenght User: {}'.format(len(user)))
print('Lenght Assistant: {}'.format(len(assistant)))

a = list()
for conversation in data:
  for utterance in conversation['utterances']:
    if utterance.get('segments'):
      for segment in utterance.get('segments'):
        a.extend(segment['annotations'])

a = list(map(lambda x: x['name'].replace('.','<>').replace('_','<>'), a))#.split('.')[0] + '_' + x['name'].split('.')[1],a))
print(len(set(a)))

"""There are 26 different types of annotation in this dataset."""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(oov_token='<OOV>', filters='\'!"#$%&()*+,-./:;=?@[\\]^_`{|}~\t\n')
tokenizer.fit_on_texts(assistant + user)

word_index = tokenizer.word_index

print('Vocabulary length: {}'.format(len(word_index)))

encoder_input = tokenizer.texts_to_sequences(user)
decoder_input = tokenizer.texts_to_sequences(assistant)
target = list()
for inp in decoder_input:
  a = inp[1:]
  a.append(0)
  target.append(a)

encoder_input = pad_sequences(encoder_input, padding='post')
decoder_input = pad_sequences(decoder_input, padding='post')
target = pad_sequences(target, padding='post')

max_encoder_len = len(encoder_input[0])
max_decoder_len = len(decoder_input[0])

print('Sample encoder:')
print(encoder_input[0])
print('Sample decoder:')
print(decoder_input[0])
print('Sample target:')
print(target[0])
print('Max length encoder: {}'.format(max_encoder_len))
print('Max length decoder: {}'.format(max_decoder_len))
print('Dataset size: {}'.format(len(encoder_input)))

dataset = tf.data.Dataset.from_tensor_slices((encoder_input, decoder_input, target))

# Batch size
BATCH_SIZE = 50
BUFFER_SIZE = 10000
dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)
print(dataset.take(1))

"""# **LSTM with ATTENTION**"""

EMBEDDING_DIM = 200
RNN_UNITS = 200
VOCAB_SIZE = len(word_index) + 1 # word_index count from 1, but keras layers count from 0

class Attention(tf.keras.layers.Layer):
  def __init__(self, attention_units):
    super().__init__()
    # Dense layer for query (encoder's hidden state)
    self.W1 = tf.keras.layers.Dense(attention_units)
    # Dense layer for value (encoder's outputs)
    self.W2 = tf.keras.layers.Dense(attention_units)
    # Dense layer to compute attention score
    self.V = tf.keras.layers.Dense(1)

  def call(self, query, values):
    # query: hidden state
    # query shape == (batch_size, rnn_units)
    # values shape == (batch_size, encoder's input length, rnn_units)
    
    # query shape == (batch_size, 1, rnn_units)
    query = tf.expand_dims(query, 1)

    # x shape == (batch_size, encoder's input length, attention_units)
    x = tf.nn.tanh(self.W1(query) + self.W2(values))
    # attention_score shape == (batch_size, encoder's input length, 1)
    attention_score = self.V(x)

    # attention_weights shape == (batch_size, encoder's input length, 1)
    attention_weights = tf.nn.softmax(attention_score, axis=1)

    # context_vector shape after sum == (batch_size, encoder's input length)
    context_vector = attention_weights * values
    context_vector = tf.reduce_sum(context_vector, axis=1)

    return context_vector

class Encoder(tf.keras.Model):
  def __init__(self, rnn_units, embedding_dim, vocab_size, batch_size = 1):
    super().__init__()
    self.batch_size = batch_size
    self.rnn_units = rnn_units
    self.embedding_dim = embedding_dim
    self.vocab_size = vocab_size
    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='encoder_embedding')
    self.LSTM = tf.keras.layers.LSTM(self.rnn_units, return_state=True, return_sequences=True, name='encoder_lstm')

  def call(self, input , hidden_state, cell_state):
    x = self.embedding(input)
    states = [hidden_state, cell_state]
    encoder_outputs, hidden_state, cell_state = self.LSTM(x, initial_state=states)
    
    return encoder_outputs, hidden_state, cell_state

  def get_initial_state(self):
    hidden_state = tf.zeros((self.batch_size, self.rnn_units))
    cell_state = tf.zeros((self.batch_size, self.rnn_units))
    
    return hidden_state, cell_state 

encoder = Encoder(RNN_UNITS, EMBEDDING_DIM, VOCAB_SIZE, BATCH_SIZE)
states = encoder.get_initial_state()

print('--- Decoder example ---')
print('Input: {}'.format(list(dataset.take(1).as_numpy_iterator())[0][0].shape))
encoder_output, encoder_h_state, encoder_c_state = encoder(list(dataset.take(1).as_numpy_iterator())[0][0], states[0], states[1])
print('Output: {}'.format(encoder_output.shape))
encoder.summary()

class Decoder(tf.keras.Model):
  def __init__(self, rnn_units, embedding_dim, vocab_size, batch_size = 1):
    super().__init__()
    self.batch_size = batch_size
    self.rnn_units = rnn_units
    self.embedding_dim = embedding_dim
    self.vocab_size = vocab_size
    self.attention = Attention(attention_units = rnn_units)
    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='decoder_embedding')
    self.LSTM = tf.keras.layers.LSTM(self.rnn_units , return_state=True , return_sequences=True, name='decoder_lstm')
    self.dense = tf.keras.layers.Dense(self.vocab_size, activation=tf.keras.activations.softmax, name='decoder_output')
    
  def call(self, query, value, input, hidden_state, cell_state):
    """
    query: hidden states got after passing through the encoder's LSTM layer
    value: predicted value at each time step in the encoder's LSTM layer
    input: batch of sequences 
    hidden_state: current hidden state of the decoder
    cell_state: current cell state of the decoder 
    
    
    """   
    # attention_vector shape (batch_size, encoder's input length)
    attention_vector = self.attention(query, value)

    # embedded shape (batch_size, decoder's input length, embedding dim)
    embedded = self.embedding(input)
    
    # x shape (batch size, 1, encoder's input length + embedding dim)
    x = tf.concat([tf.expand_dims(attention_vector, 1), embedded], axis=-1)

    # lstm_outputs shape (batch_size, 1, rnn_units)
    states = [hidden_state, cell_state]
    lstm_outputs, hidden_state, cell_state = self.LSTM(x, initial_state = states)
    
    # softmax_outputs shape (batch_size, 1, vocab_size)
    softmax_outputs = self.dense(lstm_outputs)

    return softmax_outputs, hidden_state, cell_state

  def get_initial_state(self):
    hidden_state = tf.zeros((self.batch_size, self.rnn_units))
    cell_state = tf.zeros((self.batch_size, self.rnn_units))

    return hidden_state, cell_state
  
decoder = Decoder(RNN_UNITS, EMBEDDING_DIM, VOCAB_SIZE, BATCH_SIZE)
states = decoder.get_initial_state()

# The following line is just to enable summary
print('--- Encoder example ---')
print('Input: {}'.format(list(dataset.take(1).as_numpy_iterator())[0][1].shape))

# query shape = (batch size, rnn_units*2)
query = tf.concat([encoder_h_state, encoder_c_state], axis=-1)

output, decoder_h_state, decoder_c_state = decoder(query, encoder_output ,tf.expand_dims(list(dataset.take(1).as_numpy_iterator())[0][1][:,0],1), states[0], states[1])
print('Output: {}'.format(output.shape))
encoder.summary()

"""# **Training**"""

optimizer = tf.keras.optimizers.Adam()
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

# Directory where the checkpoints will be saved
checkpoint_dir = './drive/My Drive/data/attention_checkpoint'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

@tf.function
def train_step(encoder_input, decoder_input, target):
  batch_loss = 0

  with tf.GradientTape() as tape:
    states = encoder.get_initial_state()
    encoder_output, encoder_h_state, encoder_c_state = encoder(encoder_input, states[0], states[1])

    h_state = encoder_h_state
    c_state = encoder_c_state
        
    for timestep in range(decoder_input.shape[1]):
      # query shape = (batch size, rnn_units*2)
      query = tf.concat([h_state, c_state], axis=-1)
      
      output, h_state, c_state = decoder(query, encoder_output , tf.expand_dims(decoder_input[:,timestep], 1), h_state, c_state)

      batch_loss += loss(target[:, timestep], output)
  
  variables = encoder.trainable_variables + decoder.trainable_variables
  gradients = tape.gradient(batch_loss, variables)
  optimizer.apply_gradients(zip(gradients, variables))

  return batch_loss

EPOCHS = 100

for epoch in range(EPOCHS):
  start = time.time()

  total_loss = 0

  for encoder_input, decoder_input, target in dataset:
    batch_loss = train_step(encoder_input, decoder_input, target)
    total_loss += batch_loss
    break

  checkpoint.save(file_prefix = checkpoint_prefix)

  print('Epoch {} Loss {}'.format(epoch + 1, total_loss))
  print('Time: {}'.format(time.time() - start))
  print()

"""# **Evaluate**"""

test_encoder = Encoder(RNN_UNITS, EMBEDDING_DIM, VOCAB_SIZE, 1)
test_decoder = Decoder(RNN_UNITS, EMBEDDING_DIM, VOCAB_SIZE, 1)
test_checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=test_encoder, decoder=test_decoder)
test_checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

def generate_text(question):
  states = test_encoder.get_initial_state()
  
  # Converting our question to numbers (vectorizing)
  encoder_input = tokenizer.texts_to_sequences([question])
  encoder_input = pad_sequences(encoder_input, maxlen=max_encoder_len, padding='post')
  
  encoder_output, encoder_h_state, encoder_c_state = test_encoder(encoder_input, states[0], states[1])
  
  h_state = encoder_h_state
  c_state = encoder_c_state
  decoder_input = np.zeros((1, 1)) # starting with an empty string
  decoder_input[0, 0] = tokenizer.texts_to_sequences('<start>')[0][0]
  
  response_generated = []
  temperature = 1
  count = 0
  
  while True:
    query = tf.concat([h_state, c_state], axis=-1)
    predictions, h_state, c_state = test_decoder(query, encoder_output , decoder_input, h_state, c_state)
    predictions = tf.squeeze(predictions, [1])

    # using a categorical distribution to predict the character returned by the model
    predictions = predictions / temperature
    predicted_id = np.argmax(predictions[0])

    if tokenizer.sequences_to_texts([[predicted_id]])[0] != '<eov>':
      count +=1
      de_input = tf.expand_dims([predicted_id], 0)
      response_generated.append(tokenizer.sequences_to_texts([[predicted_id]])[0])
      
      if count == 10:
        break  
    else:
      response_generated.append('\n')
      break
  
  return (' '.join(response_generated))

question = input('Customer says:')
response = generate_text(question)
print('Assistant says: {}'.format(response))